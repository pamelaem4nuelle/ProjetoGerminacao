{
  "hash": "db0772b236f55277515b7cab317f9437",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Aula 9\"\nformat: html\neditor: visual\n---\n\n\n# Análise de Modelo Misto\n\n## Parcela subdividida\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(magrittr)\nmilho <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1345524759#gid=1345524759\")\nmilho %>%  \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.05, color = \"grey\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               alpha = 0.5, color = \"blue\")+\n  facet_wrap(~ hybrid)+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(method, yield))+\n  geom_jitter(width = 0.05, color = \"grey\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               alpha = 0.5, color = \"red\")+\n  facet_wrap(~ hybrid)+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nOs subgráficos presentes nos dois gráficos permitem observar como cada híbrido responde a diferentes métodos. Pode haver diferenças significativas entre híbridos, que podem ser observadas pela comparação das distribuições, médias e intervalos de confiança entre subgráficos.\n\n## Modelo linear para parcela subdividida\n\nAjusta a raiz quadrada do índice (sqrt(index)) com efeitos fixos de hybrid, method, sua interação, e block, além de um intercepto aleatório para cada combinação de block e hybrid.\n\nApós esse ajuste, é feito a ANOVA dos efeitos fixos, deu diferença significativa e atendeu as premissas da ANOVA de normalidade e homogeneidade.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmilho <- milho %>% \n  mutate(block=as.factor(block))\nmix2 <- lmer(sqrt(index)~hybrid*method+block+(1|block/hybrid),data= milho)\n\nanova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 2.14415 0.42883  3.0632\nmethod           1 0.54438 0.54438  3.8886\nblock            3 0.01004 0.00335  0.0239\nhybrid:method    5 1.87331 0.37466  2.6762\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.971).\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias_milho <- emmeans(mix2,\n                        ~hybrid|method,\n                        type=\"response\")\nmedias_milho2 <- emmeans(mix2,\n                         ~method|hybrid,\n                         type=\"response\")\nlibrary(multcomp)\ncld(medias_milho2, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  A    \n pin        25.0 12.1 6084     6.84     54.4  A    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  A    \n silk       26.0 12.4 6084     7.42     56.0  A    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  A    \n silk       21.3 11.2 6084     5.00     48.9  A    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  A    \n pin        37.1 14.8 6084    13.79     71.8   B   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  A    \n pin        31.7 13.7 6084    10.57     64.2  A    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  A    \n pin        19.4 10.7 6084     4.10     46.0  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n## Gráfico de regressão linear\n\nPara criar o gráfico, deve ser utilizado a função **geom_smooth** (method = lm)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=401662555#gid=401662555\")\n\nestande %>% \n  ggplot(aes(trat, nplants,color))+\n  geom_jitter(width = 0.1, alpha=0.2)+\n  facet_wrap(~trat)+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\",size= 0.5, color= \"blue\")+\n  geom_smooth(method=\"lm\", se=F)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  exp1<- estande %>% \n    filter(exp==1)\n  exp1 %>% \n    ggplot(aes(trat,nplants))+\n    geom_point()+\n    ylim(0,100)+\n    geom_smooth(se=F)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n  lm1<- lm(nplants~trat,\n           data = exp1)\n  summary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n\n\n:::\n:::\n\n\n## Regressão linear simples por experimento\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2<- estande %>% \n    filter(exp==2)\n  exp2 %>% \n    ggplot(aes(trat,nplants))+\n    geom_point()+\n    ylim(0,100)+\n    geom_smooth(se=F,method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  lm2<- lm(nplants~trat,\n           data = exp2)\n  summary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3<- estande %>% \n    filter(exp==3)\n  exp3 %>% \n    ggplot(aes(trat,nplants))+\n    geom_point()+\n    ylim(0,100)+\n    geom_smooth(se=F,method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  lm3<- lm(nplants~trat,\n           data = exp3)\n  summary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n\n```{.r .cell-code}\n  hist(residuals(lm3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n## Análise Global\n\nUma análise global é uma abordagem abrangente que envolve a utilização de diversas técnicas analíticas, incluindo análise descritiva, inferencial, preditiva e diagnóstica, para obter uma visão completa e integrada de um conjunto de dados. Essa análise considera todas as variáveis relevantes e suas interações, permitindo entender padrões, tendências e relações subjacentes, além de validar e interpretar os resultados de forma holística.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm2 <- glm(nplants~trat, family=\"gaussian\",\n            data = exp1)\n\nglm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n(Intercept)         trat  \n    52.5000      -0.2419  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:\t    5330 \nResidual Deviance: 4949 \tAIC: 202\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 202.0045\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2b <- glm(nplants ~trat, family= poisson(link=\"log\"),\n             data= exp2)\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.2353\n```\n\n\n:::\n:::\n\n\nO AIC mede a qualidade de um modelo em termos de como ele equilibra a bondade de ajuste e a complexidade do modelo.\n\nQuanto menor o AIC, melhor! Na análise a cima o modelo **gaussian** se mostrou melhor que log.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nglm3 <- glm(nplants~trat, family=\"gaussian\",\n            data = exp3)\nglm3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n(Intercept)         trat  \n    95.7500      -0.7634  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:\t    6236 \nResidual Deviance: 2442 \tAIC: 185\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 185.0449\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3b <- glm(nplants ~trat, family= poisson(link=\"log\"),\n             data= exp3)\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n\nO modelo mais indicado dos dados acima foi **log**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm3 <- glmer(nplants~trat+ (trat|exp), family=\"gaussian\",\n            data = estande)\nglm3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\nREML criterion at convergence: 580.8402\nRandom effects:\n Groups   Name        Std.Dev. Corr \n exp      (Intercept) 22.5983       \n          trat         0.2349  -0.82\n Residual             12.9581       \nNumber of obs: 72, groups:  exp, 3\nFixed Effects:\n(Intercept)         trat  \n    69.7452      -0.5687  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 592.8402\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3b <- glmer(nplants ~trat+ (trat|exp), family= poisson(link=\"log\"),\n             data= estande)\n\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 660.7282\n```\n\n\n:::\n:::\n\n\nO modelo gaussiano tem o menor valor de AIC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(remotes)\nlibrary(r4pde)\nwm <- WhiteMoldSoybean\nwm %>% \n  ggplot(aes(inc, yld))+\n  geom_point()+\n  facet_wrap(~study)+\n  theme_minimal()+\n  geom_smooth(method=\"lm\", se= F)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmofo1<- lm(yld~inc,\n           data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n\n\n:::\n:::\n\n\nVisualização da relação entre a incidência da doença e o rendimento da soja em diferentes estudos, ajustando um modelo de regressão linear para quantificar essa relação.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\n wm %>% \n  group_by(study) %>% \n  do(tidy(lm(.$yld~.$inc), conf.int=TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nmofo2 <- wm %>% \n  group_by(study) %>% \n  do(tidy(lm(.$yld~.$inc), conf.int=TRUE))\nmofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n:::\n\n\nEste código ajusta modelos de regressão linear separadamente para cada estudo no conjunto de dados wm (WhiteMoldSoybean) e organiza os resultados de maneira tabular usando o pacote **broom**. Isso permite uma análise detalhada de como a incidência de mofo branco (inc) afeta o rendimento da soja (yld) em diferentes estudos. Os coeficientes e intervalos de confiança ajudam a entender a magnitude e a significância das relações para cada estudo específico.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmofo3<- lmer(yld~inc+(inc|study), data = wm, \n             REML= F)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n    npar  Sum Sq Mean Sq F value\ninc    1 5252461 5252461  141.09\n```\n\n\n:::\n\n```{.r .cell-code}\nconfint(mofo3, method=\"Wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n```\n\n\n:::\n:::\n\n\nO código ajusta um modelo linear misto para analisar a relação entre a incidência de mofo branco e o rendimento da soja, considerando as variações entre diferentes estudos. O uso de efeitos aleatórios permite capturar a variabilidade nos efeitos de inc entre os estudos. A função **summary** fornece um resumo detalhado do modelo, **anova** testa a significância dos termos, e **confint** fornece intervalos de confiança para os parâmetros, permitindo uma análise abrangente e robusta.\n\n## Correlação linear\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(patchwork)\nlibrary(tidyverse)\nimgs <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=373270992#gid=373270992\")\np1 <- imgs %>% \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\np2 <- imgs %>% \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\nimgs %>%  \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") %>%  \n  ggplot(aes(method, value))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncombined_plot <- p1 + p2\nprint(combined_plot)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\nO código fornecido cria duas visualizações de dispersão com linhas de regressão para analisar a relação entre Assess e dois métodos diferentes (ImageJ e LeafDoctor). Além disso, transforma os dados em um formato longo e cria boxplots para comparar a distribuição dos valores entre os diferentes métodos. Isso permite uma análise visual detalhada das relações entre Assess e os métodos avaliados, bem como a distribuição dos valores gerados por cada método.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimg2 <- imgs %>%  \n  dplyr::select(Assess, LeafDoctor, ImageJ)\n\nlibrary(AgroR)\ncorgraph(img2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nO código fornecido seleciona três colunas (Assess, LeafDoctor, ImageJ) de um dataframe maior (imgs) e cria um novo dataframe (img2). Em seguida, ele usa a função **corgraph** do pacote **AgroR** para gerar um gráfico de correlação, permitindo uma análise visual das relações lineares entre as variáveis selecionadas. Esse gráfico ajuda a identificar pares de variáveis que têm fortes correlações positivas ou negativas, facilitando a compreensão das relações entre as variáveis medidas.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}